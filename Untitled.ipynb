{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8516b2e5-4d45-4881-ac56-9b25891c5e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bs4) (4.14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->bs4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->bs4) (4.15.0)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7208b1e2-8a6c-4524-b93a-3061a5222b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ixml\n",
      "  Downloading ixml-0.1.0.zip (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: ixml\n",
      "  Building wheel for ixml (pyproject.toml): started\n",
      "  Building wheel for ixml (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ixml: filename=ixml-0.1.0-py3-none-any.whl size=10482 sha256=e12bad264a38ff621fb80e3d71375f68e459e45f787ba4a3ed4ff18adce13e02\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\74\\7b\\2b\\2a0954a2b147055dfb24b30d6f2cba5e64b56fc5d64f93c701\n",
      "Successfully built ixml\n",
      "Installing collected packages: ixml\n",
      "Successfully installed ixml-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ixml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8d2570-8597-490c-8502-8e0fb2b7b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af14d582-71b8-4950-9b15-ea390e6b45d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFeatureNotFound\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m webpage = requests.get(URL, headers=HEADERS)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Parse with BeautifulSoup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or \"html.parser\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Example: scrape all <h2> tags\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h2 \u001b[38;5;129;01min\u001b[39;00m soup.find_all(\u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bs4\\__init__.py:366\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    364\u001b[39m     possible_builder_class = builder_registry.lookup(*features)\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m possible_builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[32m    367\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find a tree builder with the features you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m. Do you need to install a parser library?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m             % \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(features)\n\u001b[32m    370\u001b[39m         )\n\u001b[32m    371\u001b[39m     builder_class = possible_builder_class\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n",
      "\u001b[31mFeatureNotFound\u001b[39m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&dc&qid=1760524556&rnid=8609959031&ref=sr_nr_p_n_condition-type_1&ds=v1%3At9rpJ7fSOGDjM43DA7tb2CR74smyug4Rh2omZo5%2BJJk\" # <-- replace with your target URL\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(\"out.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write header row if file is empty\n",
    "    # writer.writerow([\"Column1\", \"Column2\"])  # <-- customize columns\n",
    "\n",
    "    # Headers for request (User-Agent + Accept-Language)\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                      'Chrome/115.0.5790.98 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "\n",
    "    # Get the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")  # or \"html.parser\"\n",
    "\n",
    "    # Example: scrape all <h2> tags\n",
    "    for h2 in soup.find_all(\"h2\"):\n",
    "        text = h2.get_text(strip=True)\n",
    "        print(text)\n",
    "        writer.writerow([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e9fb96-ee2a-444c-b6b4-2c0eb21529d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFeatureNotFound\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m webpage = requests.get(URL, headers=HEADERS)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Parse with BeautifulSoup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or \"html.parser\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Example: scrape all <h2> tags\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h2 \u001b[38;5;129;01min\u001b[39;00m soup.find_all(\u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bs4\\__init__.py:366\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    364\u001b[39m     possible_builder_class = builder_registry.lookup(*features)\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m possible_builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[32m    367\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find a tree builder with the features you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m. Do you need to install a parser library?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m             % \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(features)\n\u001b[32m    370\u001b[39m         )\n\u001b[32m    371\u001b[39m     builder_class = possible_builder_class\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n",
      "\u001b[31mFeatureNotFound\u001b[39m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&dc&qid=1760524556&rnid=8609959031&ref=sr_nr_p_n_condition-type_1&ds=v1%3At9rpJ7fSOGDjM43DA7tb2CR74smyug4Rh2omZo5%2BJJk\" # <-- replace with your target URL\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(\"out.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write header row if file is empty\n",
    "    # writer.writerow([\"Column1\", \"Column2\"])  # <-- customize columns\n",
    "\n",
    "    # Headers for request (User-Agent + Accept-Language)\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                      'Chrome/115.0.5790.98 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "\n",
    "    # Get the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")  # or \"html.parser\"\n",
    "\n",
    "    # Example: scrape all <h2> tags\n",
    "    for h2 in soup.find_all(\"h2\"):\n",
    "        text = h2.get_text(strip=True)\n",
    "        print(text)\n",
    "        writer.writerow([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73188548-9bfd-411c-aa57-21b74ac44e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dd5c8b-3f3a-46c1-8f25-4afb29fe5b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Downloading lxml-6.0.2-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.8/4.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 4.6 MB/s  0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa4db2d1-a093-4422-8fac-fd733590553b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFeatureNotFound\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m webpage = requests.get(URL, headers=HEADERS)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Parse with BeautifulSoup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or \"html.parser\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Example: scrape all <h2> tags\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h2 \u001b[38;5;129;01min\u001b[39;00m soup.find_all(\u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bs4\\__init__.py:366\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    364\u001b[39m     possible_builder_class = builder_registry.lookup(*features)\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m possible_builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[32m    367\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find a tree builder with the features you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m. Do you need to install a parser library?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m             % \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(features)\n\u001b[32m    370\u001b[39m         )\n\u001b[32m    371\u001b[39m     builder_class = possible_builder_class\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n",
      "\u001b[31mFeatureNotFound\u001b[39m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&dc&qid=1760524556&rnid=8609959031&ref=sr_nr_p_n_condition-type_1&ds=v1%3At9rpJ7fSOGDjM43DA7tb2CR74smyug4Rh2omZo5%2BJJk\" # <-- replace with your target URL\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(\"out.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write header row if file is empty\n",
    "    # writer.writerow([\"Column1\", \"Column2\"])  # <-- customize columns\n",
    "\n",
    "    # Headers for request (User-Agent + Accept-Language)\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                      'Chrome/115.0.5790.98 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "\n",
    "    # Get the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")  # or \"html.parser\"\n",
    "\n",
    "    # Example: scrape all <h2> tags\n",
    "    for h2 in soup.find_all(\"h2\"):\n",
    "        text = h2.get_text(strip=True)\n",
    "        print(text)\n",
    "        writer.writerow([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb1e01d-a4ec-45cb-9fd9-bcce8f073883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c2002f-2ee0-4655-a56d-b6b235e92684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lxml\n",
      "Version: 6.0.2\n",
      "Summary: Powerful and Pythonic XML processing library combining libxml2/libxslt with the ElementTree API.\n",
      "Home-page: https://lxml.de/\n",
      "Author: lxml dev team\n",
      "Author-email: lxml@lxml.de\n",
      "License: BSD-3-Clause\n",
      "Location: C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd3e1ee-4542-4030-9aae-9f9966ce7646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a180f23-8de9-4175-8227-977857f0f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage.content, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeed14a0-204d-41c6-a057-1963ecdc13c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFeatureNotFound\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m webpage = requests.get(URL, headers=HEADERS)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Parse with BeautifulSoup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlxml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or \"html.parser\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Example: scrape all <h2> tags\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h2 \u001b[38;5;129;01min\u001b[39;00m soup.find_all(\u001b[33m\"\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\bs4\\__init__.py:366\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    364\u001b[39m     possible_builder_class = builder_registry.lookup(*features)\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m possible_builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[32m    367\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find a tree builder with the features you \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m. Do you need to install a parser library?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m             % \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(features)\n\u001b[32m    370\u001b[39m         )\n\u001b[32m    371\u001b[39m     builder_class = possible_builder_class\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n",
      "\u001b[31mFeatureNotFound\u001b[39m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&dc&qid=1760524556&rnid=8609959031&ref=sr_nr_p_n_condition-type_1&ds=v1%3At9rpJ7fSOGDjM43DA7tb2CR74smyug4Rh2omZo5%2BJJk\" # <-- replace with your target URL\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(\"out.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write header row if file is empty\n",
    "    # writer.writerow([\"Column1\", \"Column2\"])  # <-- customize columns\n",
    "\n",
    "    # Headers for request (User-Agent + Accept-Language)\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                      'Chrome/115.0.5790.98 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "\n",
    "    # Get the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")  # or \"html.parser\"\n",
    "\n",
    "    # Example: scrape all <h2> tags\n",
    "    for h2 in soup.find_all(\"h2\"):\n",
    "        text = h2.get_text(strip=True)\n",
    "        print(text)\n",
    "        writer.writerow([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136d00d4-5502-4b03-97b7-81234951aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&dc&qid=1760524556&rnid=8609959031&ref=sr_nr_p_n_condition-type_1&ds=v1%3At9rpJ7fSOGDjM43DA7tb2CR74smyug4Rh2omZo5%2BJJk\"\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(\"out.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Optional: write headers if starting fresh\n",
    "    writer.writerow([\"Product Title\"])  # you can add more columns later\n",
    "\n",
    "    # Headers for request\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                      'Chrome/115.0.5790.98 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "\n",
    "    # Get the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Parse with BeautifulSoup using built-in parser\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Amazon product titles are usually inside <span> with class 'a-size-medium a-color-base a-text-normal'\n",
    "    for product in soup.find_all(\"span\", {\"class\": \"a-size-medium a-color-base a-text-normal\"}):\n",
    "        title = product.get_text(strip=True)\n",
    "        print(title)\n",
    "        writer.writerow([title])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d466d3b-0bea-47d2-a68b-ef14a76687f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A 9,898 https://www.amazon.in/realme-Long-Lasting-Resistance-Military-Grade-Durability/dp/B0F9TT7Z5Q/ref=sr_1_1?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.KyTEmyUkiDWVSE96u7Yx_qmXwby47xpTyz-wiJjk2Ok&dib_tag=se&qid=1760525604&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m link_url = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.amazon.in\u001b[39m\u001b[33m\"\u001b[39m + link[\u001b[33m'\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m link \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(title_text, price_text, link_url)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtitle_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_url\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "for product in soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"}):\n",
    "    title = product.find(\"span\", {\"class\": \"a-size-medium a-color-base a-text-normal\"})\n",
    "    price = product.find(\"span\", {\"class\": \"a-price-whole\"})\n",
    "    link = product.find(\"a\", {\"class\": \"a-link-normal s-no-outline\"})\n",
    "\n",
    "    title_text = title.get_text(strip=True) if title else \"N/A\"\n",
    "    price_text = price.get_text(strip=True) if price else \"N/A\"\n",
    "    link_url = \"https://www.amazon.in\" + link['href'] if link else \"N/A\"\n",
    "\n",
    "    print(title_text, price_text, link_url)\n",
    "    writer.writerow([title_text, price_text, link_url])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f9456d-4f53-4c6a-8be7-acc712f0dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A 9,898 https://www.amazon.in/realme-Long-Lasting-Resistance-Military-Grade-Durability/dp/B0F9TT7Z5Q/ref=sr_1_1?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-1\n",
      "N/A 7,499 https://www.amazon.in/Redmi-A4-5G-Sparkle-Charging/dp/B0DLW427YG/ref=sr_1_2?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-2\n",
      "N/A 10,998 https://www.amazon.in/iQOO-Titanium-Dimensity-Processor-Shock-Resistance/dp/B0FC5TDB9P/ref=sr_1_3?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-3\n",
      "N/A 14,498 https://www.amazon.in/iQOO-Dimensity-Processor-Military-Grade-Durability/dp/B0F2T61RZD/ref=sr_1_4?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-4\n",
      "N/A 10,998 https://www.amazon.in/iQOO-Dimensity-Processor-Military-Shock-Resistance/dp/B0FC5XK9WZ/ref=sr_1_5?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-5\n",
      "N/A 14,498 https://www.amazon.in/iQOO-Ultramarine-Dimensity-Military-Grade-Durability/dp/B0F2T6TV4M/ref=sr_1_6?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-6\n",
      "N/A 9,898 https://www.amazon.in/realme-Long-Lasting-Resistance-Military-Grade-Durability/dp/B0F9TS623W/ref=sr_1_7?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-7\n",
      "N/A 10,999 https://www.amazon.in/Redmi-Diamond-Largest-Display-Segment/dp/B0D78Y577J/ref=sr_1_8?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-8\n",
      "N/A 8,999 https://www.amazon.in/Samsung-MediaTek-Dimensity-Charging-Upgrades/dp/B0DX655V11/ref=sr_1_9?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-9\n",
      "N/A 10,999 https://www.amazon.in/Redmi-Hawaiian-Largest-Display-Segment/dp/B0D78X544X/ref=sr_1_10?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-10\n",
      "N/A 12,998 https://www.amazon.in/iQOO-Dimensity-Processor-Military-Grade-Durability/dp/B0F2T674FJ/ref=sr_1_11?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-11\n",
      "N/A 12,998 https://www.amazon.in/iQOO-Ultramarine-Dimensity-Military-Grade-Durability/dp/B0F2T7B9TM/ref=sr_1_12?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-12\n",
      "N/A 10,999 https://www.amazon.in/Redmi-Orchid-Largest-Display-Segment/dp/B0D78X5CMJ/ref=sr_1_13?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-13\n",
      "N/A 9,998 https://www.amazon.in/iQOO-Titanium-Dimensity-Processor-Shock-Resistance/dp/B0FC5XCLXG/ref=sr_1_14?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-14\n",
      "N/A 8,349 https://www.amazon.in/Redmi-Sparkle-Storage-Segment-Charging/dp/B0DLW44CGS/ref=sr_1_15?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-15\n",
      "N/A 8,999 https://www.amazon.in/Redmi-A4-5G-Sparkle-Charging/dp/B0FBR69B2R/ref=sr_1_16?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-16\n",
      "N/A 13,999 https://www.amazon.in/Samsung-Storage-Enhanced-Unmatched-Nightography/dp/B0FDBB2VRC/ref=sr_1_17?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-17\n",
      "N/A 7,499 https://www.amazon.in/Redmi-Storage-Segment-Largest-Charging/dp/B0DLW1L5PR/ref=sr_1_18?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-18\n",
      "N/A 7,999 https://www.amazon.in/Samsung-MediaTek-Dimensity-Charging-Upgrades/dp/B0DX6P3RX9/ref=sr_1_19?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-19\n",
      "N/A 8,349 https://www.amazon.in/Redmi-A4-5G-Storage-Charging/dp/B0DLW4QD72/ref=sr_1_20?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-20\n",
      "N/A 12,998 https://www.amazon.in/iQOO-Titanium-Dimensity-Processor-Shock-Resistance/dp/B0FC5QGMZ1/ref=sr_1_21?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-21\n",
      "N/A 7,198 https://www.amazon.in/realme-6300mAh-Segments-Biggest-Battery/dp/B0FG2NDHJM/ref=sr_1_22?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-22\n",
      "N/A N/A https://www.amazon.in/iQOO-Dimensity-Processor-Military-Shock-Resistance/dp/B0FC5TBWG5/ref=sr_1_23?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-23\n",
      "N/A 8,999 https://www.amazon.in/Redmi-A4-5G-Storage-Charging/dp/B0FBRM15FH/ref=sr_1_24?dib=eyJ2IjoiMSJ9.7zq4SGsfvqabYxYN7ri7SI4hFrjV_Qc2nBrNcpM_suQFbq2v-_d0Opmh4Vx6kBp9I59G0fPqBiwd8rhqlx4Rm3PoStltkSbLDv6wwJ_cKxvmisDDg2L6niTxuQ62P1z9Y_tKCyTHXQXZay3X1QR95j7J1XyPaqd4WehzbNADP_-rNT8YjxqvkTdtVMB3tthBcKw3nmWGQPNHDEo8t44hc4vIzp-04btruydICQyV1mD9-egRZd3aMbl8Uiafu7zhfNjb7r_LK2Z_rQJ_kt2SxnEcQQPn7xXLfxbexEYqGnw.kWCAOXFTN1YQOgkY4IKw4IRi3u8mke0eQSFwdySLODk&dib_tag=se&qid=1760525964&refinements=p_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&rnid=8609959031&s=electronics&sr=1-24\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031&dc&qid=1760524556&rnid=8609959031&ref=sr_nr_p_n_condition-type_1&ds=v1%3At9rpJ7fSOGDjM43DA7tb2CR74smyug4Rh2omZo5%2BJJk\"\n",
    "\n",
    "# Open CSV file in append mode\n",
    "with open(\"out.csv\", \"a\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Optional: write headers if starting fresh\n",
    "    writer.writerow([\"Product Title\", \"Price\", \"Link\"])  \n",
    "\n",
    "    # Headers for request\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) ' +\n",
    "                      'Chrome/115.0.5790.98 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9'\n",
    "    }\n",
    "\n",
    "    # Get the webpage\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Loop through products\n",
    "    for product in soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"}):\n",
    "        title = product.find(\"span\", {\"class\": \"a-size-medium a-color-base a-text-normal\"})\n",
    "        price = product.find(\"span\", {\"class\": \"a-price-whole\"})\n",
    "        link = product.find(\"a\", {\"class\": \"a-link-normal s-no-outline\"})\n",
    "\n",
    "        title_text = title.get_text(strip=True) if title else \"N/A\"\n",
    "        price_text = price.get_text(strip=True) if price else \"N/A\"\n",
    "        link_url = \"https://www.amazon.in\" + link['href'] if link else \"N/A\"\n",
    "\n",
    "        print(title_text, price_text, link_url)\n",
    "        writer.writerow([title_text, price_text, link_url])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adcaab10-639b-4e25-a30c-2d21f7f001c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9ed945c-c40f-4272-800a-37c235d89eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.36.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.30.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (25.4.0)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.30.0->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (3.11)\n",
      "Collecting outcome (from trio<1.0,>=0.30.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (2.0.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.30.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.36.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 9.6/9.6 MB 49.2 MB/s  0:00:00\n",
      "Downloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, trio, trio-websocket, selenium\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [wsproto]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------------- 7/7 [selenium]\n",
      "\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.36.0 sortedcontainers-2.4.0 trio-0.31.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b930761-6858-4f92-8c5f-ebdbcda9b49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fc0dacb-bb4d-4da6-b6d6-bf2b178a4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.140 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")  # no lxml needed\n",
    "\n",
    "with open(\"out.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Title\", \"Price\", \"Link\", \"Image\"])\n",
    "\n",
    "    for product in soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"}):\n",
    "        title = product.find(\"span\", class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "        price = product.find(\"span\", class_=\"a-price-whole\")\n",
    "        link = product.find(\"a\", class_=\"a-link-normal s-no-outline\")\n",
    "        image = product.find(\"img\", class_=\"s-image\")\n",
    "\n",
    "        writer.writerow([\n",
    "            title.get_text(strip=True) if title else \"N/A\",\n",
    "            price.get_text(strip=True) if price else \"N/A\",\n",
    "            \"https://www.amazon.in\" + link['href'] if link else \"N/A\",\n",
    "            image['src'] if image else \"N/A\"\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78150b69-72a0-4333-a6c6-7bf9f30170de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! CSV file saved as out.csv in the current folder.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Amazon URL to scrape\n",
    "URL = \"https://www.amazon.in/s?i=electronics&rh=n%3A976419031%2Cp_36%3A630000-1500000%2Cp_n_condition-type%3A8609960031\"\n",
    "\n",
    "# Headers to mimic a real browser\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                  \"(KHTML, like Gecko) Chrome/116.0.5845.140 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Open CSV file in write mode\n",
    "with open(\"out.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Product Name\", \"Price\", \"Link\", \"Image URL\"])  # header row\n",
    "\n",
    "    # Loop through all products\n",
    "    for product in soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"}):\n",
    "        # Get product title\n",
    "        title = product.find(\"span\", class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "        # Fallback: sometimes title is inside h2 tag if class changes\n",
    "        if not title:\n",
    "            title_tag = product.find(\"h2\")\n",
    "            title = title_tag.get_text(strip=True) if title_tag else \"N/A\"\n",
    "        else:\n",
    "            title = title.get_text(strip=True)\n",
    "        \n",
    "        # Get product price\n",
    "        price = product.find(\"span\", class_=\"a-price-whole\")\n",
    "        price = price.get_text(strip=True) if price else \"N/A\"\n",
    "\n",
    "        # Get product link\n",
    "        link_tag = product.find(\"a\", class_=\"a-link-normal s-no-outline\")\n",
    "        link = \"https://www.amazon.in\" + link_tag['href'] if link_tag else \"N/A\"\n",
    "\n",
    "        # Get product image\n",
    "        image_tag = product.find(\"img\", class_=\"s-image\")\n",
    "        image = image_tag['src'] if image_tag else \"N/A\"\n",
    "\n",
    "        # Write row in CSV\n",
    "        writer.writerow([title, price, link, image])\n",
    "\n",
    "print(\"Scraping complete! CSV file saved as out.csv in the current folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd71fb-24b7-46bb-bb69-e3884f5958d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
